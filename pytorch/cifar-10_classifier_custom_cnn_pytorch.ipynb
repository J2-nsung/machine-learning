{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA0-2fcbNgzU"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoIfvgBGKuFk"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhZOC7VLNecj"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T9h0ScsNVIa"
      },
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 100\n",
        "num_epochs = 100\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK4ti9cpNi4-"
      },
      "source": [
        "## Make Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aswrSJ8elmYl"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_all = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "n_val = int(len(train_data_all) * 0.2)\n",
        "n_train = len(train_data_all) - n_val\n",
        "\n",
        "train_data, valid_data = random_split(train_data_all, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    valid_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRsZJICg99Mi",
        "outputId": "e46817b9-86d0-4e4d-b522-a900b09536cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "u5aESdoY-c71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1),  # (32, 32, 32)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2) # (16, 16, 32)\n",
        "        )\n",
        "\n",
        "        self.layer_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),  # (16, 16, 64)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # (8, 8, 64)\n",
        "        )\n",
        "\n",
        "        self.layer_3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),  # (8, 8, 128)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2) # (4, 4, 128)\n",
        "        )\n",
        "        \n",
        "        self.fc_1 = nn.Linear(4*4*128, 64)\n",
        "        self.fc_2 = nn.Linear(64, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = self.layer_3(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # flatten\n",
        "        x = self.fc_1(x)\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "7c-CQFmJ-cLx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm7sI3VTlM1y"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ4tz7CHlLii"
      },
      "source": [
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JkCbMzvk4jG",
        "outputId": "a86e5e2d-4722-459e-baba-8c08af67674b"
      },
      "source": [
        "best_model_weights = copy.deepcopy(model.state_dict())\n",
        "early_stop = 5\n",
        "stop_count = 0\n",
        "best_acc = 0.0\n",
        "\n",
        "dataloaders = {'train': train_loader, 'val': valid_loader}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print()\n",
        "    print(f'[Epoch {epoch+1}/{num_epochs}]')\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "        else:\n",
        "            model.eval()\n",
        "\n",
        "        step_loss = 0.0\n",
        "        correct_count = 0\n",
        "\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # train일 경우 loss, optimizer를 업데이트\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                preds = torch.argmax(outputs, dim=-1)\n",
        "                loss = criterion(outputs, labels)\n",
        "            \n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            step_loss += loss.item() * inputs.size(0)\n",
        "            correct_count += torch.sum(preds == labels)\n",
        "        \n",
        "        epoch_loss = step_loss / len(dataloaders[phase].dataset)\n",
        "        epoch_acc = correct_count.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "        print(f\"{phase} Loss: {epoch_loss:.3f} Acc: {epoch_acc:.3f}\")\n",
        "\n",
        "        if phase == 'val' and best_acc < epoch_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_weights = copy.deepcopy(model.state_dict())\n",
        "            stop_count = 0\n",
        "            print('...best weigths update!...')\n",
        "\n",
        "        elif phase == 'val' and best_acc >= epoch_acc:\n",
        "            stop_count += 1\n",
        "\n",
        "    if early_stop == stop_count:\n",
        "        print()\n",
        "        print(\"Early Stopping...\")\n",
        "        break\n",
        "\n",
        "print(f\"Best validation Accuracy: {100*best_acc:.3f}%\")\n",
        "model.load_state_dict(best_model_weights)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Epoch 1/100]\n",
            "train Loss: 1.394 Acc: 0.498\n",
            "val Loss: 1.114 Acc: 0.603\n",
            "...best weigths update!...\n",
            "\n",
            "[Epoch 2/100]\n",
            "train Loss: 0.974 Acc: 0.657\n",
            "val Loss: 0.943 Acc: 0.674\n",
            "...best weigths update!...\n",
            "\n",
            "[Epoch 3/100]\n",
            "train Loss: 0.798 Acc: 0.724\n",
            "val Loss: 0.870 Acc: 0.703\n",
            "...best weigths update!...\n",
            "\n",
            "[Epoch 4/100]\n",
            "train Loss: 0.686 Acc: 0.761\n",
            "val Loss: 0.812 Acc: 0.723\n",
            "...best weigths update!...\n",
            "\n",
            "[Epoch 5/100]\n",
            "train Loss: 0.597 Acc: 0.792\n",
            "val Loss: 0.827 Acc: 0.724\n",
            "...best weigths update!...\n",
            "\n",
            "[Epoch 6/100]\n",
            "train Loss: 0.521 Acc: 0.818\n",
            "val Loss: 0.770 Acc: 0.749\n",
            "...best weigths update!...\n",
            "\n",
            "[Epoch 7/100]\n",
            "train Loss: 0.450 Acc: 0.842\n",
            "val Loss: 0.792 Acc: 0.749\n",
            "\n",
            "[Epoch 8/100]\n",
            "train Loss: 0.387 Acc: 0.864\n",
            "val Loss: 0.816 Acc: 0.750\n",
            "...best weigths update!...\n",
            "\n",
            "[Epoch 9/100]\n",
            "train Loss: 0.331 Acc: 0.885\n",
            "val Loss: 0.840 Acc: 0.748\n",
            "\n",
            "[Epoch 10/100]\n",
            "train Loss: 0.281 Acc: 0.901\n",
            "val Loss: 0.925 Acc: 0.745\n",
            "\n",
            "[Epoch 11/100]\n",
            "train Loss: 0.240 Acc: 0.913\n",
            "val Loss: 1.005 Acc: 0.737\n",
            "\n",
            "[Epoch 12/100]\n",
            "train Loss: 0.204 Acc: 0.927\n",
            "val Loss: 1.122 Acc: 0.730\n",
            "\n",
            "[Epoch 13/100]\n",
            "train Loss: 0.180 Acc: 0.935\n",
            "val Loss: 1.192 Acc: 0.738\n",
            "\n",
            "Early Stopping...\n",
            "Best validation Accuracy: 75.010%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Test Data"
      ],
      "metadata": {
        "id": "ddYHhQKoHhvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbe3FjN3HfT5",
        "outputId": "f649a1ed-4be4-46b9-aa6c-1b4cb42b9644"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "dVAlUTQZHnfI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAYjzAFjlfdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a10436da-03d3-49fc-c6d4-5c42925613c8"
      },
      "source": [
        "# Entire accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (pred == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100*correct / total:.3f}%')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.400%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class accuracy\n",
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "\n",
        "        for label, prediction in zip(labels, pred):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    class_accuracy = 100 * correct_count / total_pred[classname]\n",
        "    print(f\"Accuracy for class {classname} is: {class_accuracy:.3f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMOkyc9QDbOQ",
        "outputId": "85737a01-18c3-4e2f-92b8-ab743eaf11d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class plane is: 78.800%\n",
            "Accuracy for class car is: 89.400%\n",
            "Accuracy for class bird is: 70.000%\n",
            "Accuracy for class cat is: 57.100%\n",
            "Accuracy for class deer is: 77.600%\n",
            "Accuracy for class dog is: 58.100%\n",
            "Accuracy for class frog is: 78.100%\n",
            "Accuracy for class horse is: 77.400%\n",
            "Accuracy for class ship is: 85.100%\n",
            "Accuracy for class truck is: 82.400%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E3YReG1OGCHB"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}