{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvS-_BEBLW_w",
    "outputId": "7d3fc6e4-5441-479e-8860-55f2db7e50fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvNMI-czLbas",
    "outputId": "00b7231b-c749-44e6-9052-b3212540fec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "cd drive/MyDrive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4eIf_tYJoQe"
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X1XPcYYTHMRS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tqdm as tqdm\n",
    "\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import missingno as msno # null data를 보여줌\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P4WAm4KaTdz"
   },
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkOpBDF5aTye"
   },
   "outputs": [],
   "source": [
    "seed = 0\n",
    "num_epochs = 100\n",
    "lr = 1e-4\n",
    "early_stop_count = 10\n",
    "batch_size = 32\n",
    "num_workers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gN1EukjKJjRr"
   },
   "source": [
    "## Seed fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9LmdBBcIlDE"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    동일한 조건으로 학습 시, 동일한 결과를 얻기 위해 seed 고정.\n",
    "\n",
    "    Args:\n",
    "        seed: seed 정수값.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zept6_slIrW2"
   },
   "outputs": [],
   "source": [
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kp0M8ZIvSSf4"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5O271pSjLoPI"
   },
   "outputs": [],
   "source": [
    "img_dir = './data/input/train'\n",
    "images = sorted(os.listdir(img_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzaxd3yxL5NB"
   },
   "outputs": [],
   "source": [
    "categories={}\n",
    "for image in images:\n",
    "    dir=os.path.join(img_dir, image, '*.jpg')\n",
    "    categories[image]=len(glob.glob(dir))\n",
    "\n",
    "print('Number of categories:', len(categories))\n",
    "print('-'*30)\n",
    "for cls in categories.keys():\n",
    "    print(f'Number of {cls} class:', categories[cls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8iixUPWObqR"
   },
   "outputs": [],
   "source": [
    "file_cat={\n",
    "    'dog' : 0,\n",
    "    'elephant' : 1,\n",
    "    'giraffe' : 2,\n",
    "    'guitar' : 3,\n",
    "    'horse' : 4,\n",
    "    'house' : 5,\n",
    "    'person' : 6\n",
    "}\n",
    "\n",
    "cat_hist=np.zeros(7, dtype=int)\n",
    "for cat, label in file_cat.items():\n",
    "    cat_hist[label]=categories[cat]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "df = pd.DataFrame({'Categories': images, 'Number of classes': cat_hist})\n",
    "df = df.sort_values('Number of classes', 0, False)\n",
    "\n",
    "plt.title('category distribution of train set')\n",
    "plot_1 = sns.barplot(x='Number of classes', y='Categories', data=df, label='Total', color='b')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEY70MJ5RHZA"
   },
   "outputs": [],
   "source": [
    "sorted_temp_df = df.sort_index()\n",
    "sorted_temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiTha3mfWEQR"
   },
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-JtTIPjWD1p"
   },
   "outputs": [],
   "source": [
    "def get_transforms(need=('train', 'val'), img_size=(227, 227), mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = A.Compose([\n",
    "            A.Resize(img_size[0], img_size[1], p=1.0),\n",
    "            A.Rotate(limit=30),\n",
    "            A.HorizontalFlip(),\n",
    "            A.RandomBrightnessContrast(),\n",
    "            A.Cutout(num_holes=20, max_h_size=10, max_w_size=10),\n",
    "            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    if 'val' in need:\n",
    "        transformations['val'] = A.Compose([\n",
    "            A.Resize(img_size[0], img_size[1], p=1.0),\n",
    "            A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    return transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HqjNUEjJugJ"
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dyBg7VGJS4A"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    num_classes = 7\n",
    "    _file_cat={\n",
    "        'dog' : 0,\n",
    "        'elephant' : 1,\n",
    "        'giraffe' : 2,\n",
    "        'guitar' : 3,\n",
    "        'horse' : 4,\n",
    "        'house' : 5,\n",
    "        'person' : 6\n",
    "    }\n",
    "    img_paths=[] # 이미지 경로\n",
    "    cat_labels=[] # category별 label\n",
    "\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir=img_dir\n",
    "        self.mean=mean\n",
    "        self.std=std\n",
    "        self.transform=transform\n",
    "        \n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform=None):\n",
    "        self.transform=transform\n",
    "\n",
    "    # 이미지마다 경로, label을 저장해준다.\n",
    "    def setup(self):\n",
    "        for cat, label in self._file_cat.items():\n",
    "            img_path = glob.glob(os.path.join(self.img_dir, cat, '*.jpg'))\n",
    "            for path in img_path:\n",
    "                if os.path.exists(path):\n",
    "                    self.img_paths.append(path)\n",
    "                    self.cat_labels.append(label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "\n",
    "        cat_labels = self.cat_labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            img_transform = self.transform(image=np.array(img))['image']\n",
    "        else:\n",
    "            img_transform = img\n",
    "        return img_transform, cat_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-FXlruwV01F"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "mean, std = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "img_dir = './data/input/train'\n",
    "\n",
    "transform = get_transforms(mean=mean, std=std)\n",
    "\n",
    "dataset = CustomDataset(img_dir=img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU82REPKYIIU"
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccKvj11fWVxL"
   },
   "outputs": [],
   "source": [
    "# train, validation\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(seed))\n",
    "train_dataset.dataset.set_transform(transform['train'])\n",
    "val_dataset.dataset.set_transform(transform['val'])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvsbBwilYw1F"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80h7yLehYaIM"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWxb76o_YwQz"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs):\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    early_stop = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        since = time.time()\n",
    "        \n",
    "        # phase check\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval() # train, validation split\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # train일 경우 loss, optimizer를 업데이트 해준다.\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.argmax(outputs, dim=-1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # phase별 loss 계산\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            # epoch당 loss계산                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                early_stop = 0\n",
    "                print(f'...best weights update!... {best_acc}')\n",
    "\n",
    "            # early stop (validation accuracy가 오르지 않으면 count + 1)\n",
    "            elif phase == 'val' and epoch_acc <= best_acc:\n",
    "                early_stop += 1\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step(best_acc)\n",
    "\n",
    "        # train time check\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
    "        print()\n",
    "\n",
    "        # early stopping\n",
    "        if early_stop >= early_stop_count:\n",
    "            print('...Early Stopping...')\n",
    "            print()\n",
    "            break\n",
    "        \n",
    "    print(f'Best val Acc: {best_acc}')\n",
    "    \n",
    "    # best weights load\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqbrnVE0Y-YQ"
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlQwNbr_Y9VK"
   },
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes=7, smoothing=0.5, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iRNB_PQNZA5z"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import timm\n",
    "\n",
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MuCs056ZMJ7"
   },
   "outputs": [],
   "source": [
    "model = timm.create_model('swsl_resnext50_32x4d', pretrained=True, num_classes=7).to(device)\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "criterion = LabelSmoothingLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FE1gGjNYapPk"
   },
   "outputs": [],
   "source": [
    "model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-LCxbL1eqoA"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skYhcEmiavZb"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7Ybm0OnevZ6"
   },
   "outputs": [],
   "source": [
    "test_dir = './data/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3-wMpeTevYQ"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(test_dir, 'test_answer_sample_.csv'))\n",
    "image_paths = sorted(glob.glob(os.path.join(test_dir, 'test/0', '*.jpg')))\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(227, 227, p=1.0),\n",
    "    A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),                          \n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_dataset = TestDataset(image_paths, test_transform)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5tTkV8kevWA"
   },
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "for images in test_loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        pred = model(images)\n",
    "        pred = pred.argmax(dim=-1)\n",
    "        all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "submission['answer value'] = all_predictions\n",
    "\n",
    "# 제출 파일 저장.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Pki-kvfevK6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
