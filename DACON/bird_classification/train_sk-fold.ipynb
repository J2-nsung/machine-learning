{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c5ede98-2aa6-44f9-8e98-6217a55ac669",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2dbc7-33e7-4785-80bd-3a7302484ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import logging.handlers\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import ttach as tta\n",
    "import timm\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from ml_decoder import *\n",
    "from cutmix import cutmix\n",
    "from loss import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b8070-37a3-427e-93ce-bea406b410aa",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7081b-08d7-402a-8fe0-f45166e74941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "       # \"model_name\": \"caformer_b36.sail_in22k_ft_in1k_384\",\n",
    "       \"model_name\": \"eva02_large_patch14_448.mim_in22k_ft_in22k_in1k\",\n",
    "       # \"model_name\": \"tf_efficientnetv2_xl.in21k_ft_in1k\",\n",
    "       \"seed\": 42,\n",
    "       \"num_epochs\": 50,\n",
    "       \"skf_n_splits\": 5,\n",
    "       \"lr\": 1e-5,\n",
    "       \"early_stop_count\": 5,\n",
    "       \"batch_size\": 8,\n",
    "       \"num_workers\": 8,\n",
    "       \"imgsz\": (448, 448)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8cf20b-f200-44bd-ada2-246fed25fcec",
   "metadata": {},
   "source": [
    "# Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4bc44f-228e-4a7a-821f-79926c6c2a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "log_fileHandler = logging.handlers.RotatingFileHandler(\n",
    "    filename=f\"./{CFG['model_name']}.log\",\n",
    "    maxBytes=1024000,\n",
    "    backupCount=3,\n",
    "    mode='a')\n",
    "\n",
    "log_fileHandler.setFormatter(formatter)\n",
    "logger.addHandler(log_fileHandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d35c3-f749-464f-886b-5a7576719640",
   "metadata": {},
   "source": [
    "# Fix Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f8962-a4c9-46ad-916f-e08e9e9871dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "seed_everything(CFG['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90cac8-a1e3-4418-95dc-e45593c99e30",
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2d3e1-3b12-47e2-bbde-7c53707cd3e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_size = CFG['imgsz']\n",
    "mean=(0.485, 0.456, 0.406)\n",
    "std=(0.229, 0.224, 0.225)\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(img_size[0], img_size[1], p=1.0),\n",
    "    A.Rotate(limit=30),\n",
    "    A.HorizontalFlip(),\n",
    "    A.RandomBrightnessContrast(),\n",
    "    A.Cutout(num_holes=30, max_h_size=20, max_w_size=20),\n",
    "    A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(img_size[0], img_size[1], p=1.0),\n",
    "    A.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af621a1c-c7a1-45ff-99ea-6368a5744cb1",
   "metadata": {},
   "source": [
    "# Define Categories(Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431296f9-83ea-4a02-a12d-0dfdc0347cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1cdab-3729-407d-9928-0ee7df6b055e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG['num_classes'] = len(train_df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd978a2-d06b-434f-98df-4e22f76b7aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categories = {}\n",
    "for i, c in enumerate(train_df['label'].unique()):\n",
    "    categories[c] = i\n",
    "\n",
    "categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01735e77-cd75-4913-a0f7-41bfc0a47f73",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24283eac-1687-4f3a-903c-bea3c2feccb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # origin image\n",
    "        img_path = self.df.iloc[idx]['img_path']\n",
    "        image = cv2.imread(os.path.join('./data', img_path))\n",
    "        \n",
    "        label = self.df.iloc[idx]['label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))['image']\n",
    "        \n",
    "        return image, categories[label]\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc4906-8883-449b-9682-776b09f2f887",
   "metadata": {},
   "source": [
    "# Custom model with timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb627280-ec36-4641-81f3-8561882ce805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use ML-Decoder\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=True).to(CFG['device'])\n",
    "        self.model.conv_head = nn.Identity()\n",
    "        \n",
    "        self.ml_decoder_head = MLDecoder(num_classes=CFG['num_classes'],\n",
    "                                         decoder_embedding=768,\n",
    "                                         initial_num_features=self.model.embed_dim).to(CFG['device'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model.forward_features(x)\n",
    "        x = self.ml_decoder_head(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb46ef50-e001-4e27-a89d-5f765957e8f5",
   "metadata": {},
   "source": [
    "# Train(Stratified K-Fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553b2e2a-3a1a-4765-8d16-1d2568809d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "whole_start = time.time()\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=CFG['skf_n_splits'], \n",
    "                             random_state=CFG['seed'],\n",
    "                             test_size=0.15)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=CFG['skf_n_splits'],\n",
    "#                       random_state=CFG['seed'],\n",
    "#                       shuffle=True)\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(sss.split(train_df, train_df['label'])):  \n",
    "    if fold_idx < 3:\n",
    "        continue\n",
    "        \n",
    "    print(f'----- Fold {fold_idx} -----')\n",
    "    logger.info(f'----- Fold {fold_idx} -----')\n",
    "    \n",
    "    # Create Dataset(fold)\n",
    "    X_train_fold = train_df.loc[train_idx, :]\n",
    "    X_val_fold = train_df.loc[val_idx, :]\n",
    "    \n",
    "    train_dataset = CustomDataset(X_train_fold, transform=train_transform)\n",
    "    val_dataset = CustomDataset(X_val_fold, transform=val_transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,\n",
    "                                  batch_size=CFG['batch_size'],\n",
    "                                  num_workers=CFG['num_workers'],\n",
    "                                  shuffle=True)\n",
    "\n",
    "    val_dataloader = DataLoader(val_dataset,\n",
    "                                batch_size=CFG['batch_size'],\n",
    "                                num_workers=CFG['num_workers'],\n",
    "                                shuffle=False)\n",
    "    \n",
    "    model = CustomModel(CFG['model_name'])\n",
    "    # model = timm.create_model(CFG['model_name'], pretrained=True, num_classes=CFG['num_classes']).to(CFG['device'])\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "    criterion1 = DiceLoss(mode='multiclass')\n",
    "    criterion2 = LabelSmoothingLoss(CFG['num_classes'], smoothing=0.3)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CFG['lr'])\n",
    "\n",
    "    best_score = 0.0\n",
    "    early_stop_check = 0\n",
    "    best_epoch = None\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(CFG['num_epochs']):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "\n",
    "        for inputs, labels in tqdm.tqdm(train_dataloader, leave=True):\n",
    "            inputs = inputs.to(CFG['device'])\n",
    "            labels = labels.to(CFG['device'])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if np.random.rand() >= 0.5:\n",
    "                inputs, labels_a, labels_b, lam = cutmix(inputs, labels)\n",
    "                outputs = model(inputs)\n",
    "                # loss = criterion(outputs, labels_a) * lam + criterion(outputs, labels_b) * (1 - lam)\n",
    "                loss = criterion2(outputs, labels_a) * lam + criterion2(outputs, labels_b) * (1 - lam)\n",
    "\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                # loss = criterion(outputs, labels)\n",
    "                loss = 0.25 * criterion1(outputs, labels) + 0.75 * criterion2(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_preds = []\n",
    "            targets = []\n",
    "\n",
    "            for inputs, labels in tqdm.tqdm(val_dataloader, leave=True):\n",
    "                inputs = inputs.to(CFG['device'])\n",
    "                labels = labels.to(CFG['device'])\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                preds = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "                val_preds += preds.detach().cpu().numpy().tolist()\n",
    "                targets += labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "            val_score = f1_score(targets, val_preds, average='macro')\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{CFG['num_epochs']}] Loss: {np.mean(train_loss):.6f} Val F1 Score: {val_score:.6f}\")\n",
    "\n",
    "        logger.info(f\"Epoch [{epoch+1}/{CFG['num_epochs']}] Loss: {np.mean(train_loss):.6f} Val F1 Score: {val_score:.6f}\\n\")\n",
    "\n",
    "        # save best model\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "\n",
    "            if not os.path.exists('./checkpoints'):\n",
    "                os.makedirs('./checkpoints')\n",
    "\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), f'./checkpoints/{CFG[\"model_name\"]}_fold{fold_idx}_best.pth')\n",
    "            print(f\"Save Best Weights...\")\n",
    "\n",
    "            early_stop_check = 0\n",
    "            best_epoch = epoch + 1 \n",
    "\n",
    "        else:\n",
    "            early_stop_check += 1\n",
    "\n",
    "        if early_stop_check == CFG['early_stop_count']:\n",
    "            print(\"Early Stopping...\")\n",
    "            break\n",
    "            \n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "\n",
    "    hour, remainder = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    print(f\"  - {fold_idx} fold's best epoch is '{best_epoch}'\")\n",
    "    print(f\"  - {fold_idx} fold's best score is {best_score:.6f}\")\n",
    "    print(f\"  - {fold_idx} fold's Training Time is {hour}h {minutes}m {seconds:.4f}s\")\n",
    "    print()\n",
    "\n",
    "    logger.info(f\"  - {fold_idx} fold's best epoch is '{best_epoch}'\")\n",
    "    logger.info(f\"  - {fold_idx} fold's best score is {best_score:.6f}\")\n",
    "    logger.info(f\"  - {fold_idx} fold's Training Time is {hour}h {minutes}m {seconds:.4f}s\")\n",
    "    \n",
    "    # Memory release\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    break\n",
    "\n",
    "# end training\n",
    "whole_end = time.time()\n",
    "whole_elapsed_time = whole_end - whole_start\n",
    "\n",
    "whole_hour, whole_remainder = divmod(whole_elapsed_time, 3600)\n",
    "whole_minutes, whole_seconds = divmod(whole_remainder, 60)\n",
    "\n",
    "logger.info(f\"  - Whole Training Time is {whole_hour}h {whole_minutes}m {whole_seconds:.4f}s\")\n",
    "\n",
    "# model.load_state_dict(best_model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a770a1-db78-4f6e-ac2e-e8dcc82f6265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "js",
   "language": "python",
   "name": "js"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
