{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import os, shutil\n",
    "from keras.applications import VGG16\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jinsung\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jinsung\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jinsung\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jinsung\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jinsung\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jinsung\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False, # 네트워크 최종 완전 연결 분류기 포함여부\n",
    "                  input_shape=(150, 150, 3)) # 입력영상 크기. 설정하지 않으면 알아서 처리해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './datasets/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(directory, target_size=(150, 150), batch_size=batch_size, class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)\n",
    "\n",
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jinsung\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Jinsung\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Jinsung\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.6030 - acc: 0.6655 - val_loss: 0.4549 - val_acc: 0.7910\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4342 - acc: 0.8010 - val_loss: 0.3917 - val_acc: 0.8180\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3663 - acc: 0.8340 - val_loss: 0.3251 - val_acc: 0.8720\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3153 - acc: 0.8695 - val_loss: 0.3026 - val_acc: 0.8850\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2869 - acc: 0.8805 - val_loss: 0.2873 - val_acc: 0.8820\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2658 - acc: 0.9015 - val_loss: 0.2766 - val_acc: 0.8920\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2520 - acc: 0.9030 - val_loss: 0.2701 - val_acc: 0.8860\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2352 - acc: 0.9115 - val_loss: 0.2623 - val_acc: 0.8960\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2109 - acc: 0.9235 - val_loss: 0.2565 - val_acc: 0.8920\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2111 - acc: 0.9200 - val_loss: 0.2519 - val_acc: 0.8980\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2017 - acc: 0.9260 - val_loss: 0.2498 - val_acc: 0.8920\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1915 - acc: 0.9335 - val_loss: 0.2472 - val_acc: 0.8970\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1808 - acc: 0.9395 - val_loss: 0.2443 - val_acc: 0.8970\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1678 - acc: 0.9455 - val_loss: 0.2413 - val_acc: 0.8980\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1641 - acc: 0.9405 - val_loss: 0.2449 - val_acc: 0.9010\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1590 - acc: 0.9445 - val_loss: 0.2380 - val_acc: 0.8990\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1510 - acc: 0.9460 - val_loss: 0.2467 - val_acc: 0.8960\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1472 - acc: 0.9485 - val_loss: 0.2408 - val_acc: 0.8980\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1404 - acc: 0.9515 - val_loss: 0.2364 - val_acc: 0.8970\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1343 - acc: 0.9570 - val_loss: 0.2349 - val_acc: 0.8980\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1285 - acc: 0.9565 - val_loss: 0.2356 - val_acc: 0.8970\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1274 - acc: 0.9610 - val_loss: 0.2384 - val_acc: 0.9010\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1185 - acc: 0.9610 - val_loss: 0.2376 - val_acc: 0.9010\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1151 - acc: 0.9645 - val_loss: 0.2346 - val_acc: 0.9000\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1084 - acc: 0.9665 - val_loss: 0.2493 - val_acc: 0.9030\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1063 - acc: 0.9690 - val_loss: 0.2367 - val_acc: 0.8960\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1006 - acc: 0.9705 - val_loss: 0.2491 - val_acc: 0.9040\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1004 - acc: 0.9700 - val_loss: 0.2390 - val_acc: 0.8980\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0930 - acc: 0.9730 - val_loss: 0.2417 - val_acc: 0.9000\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0914 - acc: 0.9720 - val_loss: 0.2402 - val_acc: 0.8990\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels, epochs=30, batch_size=20,\n",
    "                   validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# 검증 데이터는 증식되어서는 안됨\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tunning\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# trainable을 true로 설정해야 base network 훈련이 가능함\n",
    "conv_base.trainable = True\n",
    "\n",
    "# block5_conv1 다시 학습\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    # 타깃 디렉터리\n",
    "    train_dir,\n",
    "    # 모든 이미지의 크기를 150 * 150으로 변경\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    # binary_crossentropy 손실을 사용하므로 이진 레이블이 필요합니다\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 569s 6s/step - loss: 0.4639 - acc: 0.7935 - val_loss: 0.2931 - val_acc: 0.8910\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 567s 6s/step - loss: 0.2898 - acc: 0.8770 - val_loss: 0.2556 - val_acc: 0.8870\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 583s 6s/step - loss: 0.2490 - acc: 0.9005 - val_loss: 0.2352 - val_acc: 0.8940\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 567s 6s/step - loss: 0.2180 - acc: 0.9095 - val_loss: 0.2288 - val_acc: 0.9030\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 563s 6s/step - loss: 0.1911 - acc: 0.9245 - val_loss: 0.1828 - val_acc: 0.9240\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 567s 6s/step - loss: 0.1678 - acc: 0.9295 - val_loss: 0.1809 - val_acc: 0.9270\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 587s 6s/step - loss: 0.1491 - acc: 0.9385 - val_loss: 0.1765 - val_acc: 0.9250\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 565s 6s/step - loss: 0.1397 - acc: 0.9510 - val_loss: 0.2116 - val_acc: 0.9090\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 584s 6s/step - loss: 0.1194 - acc: 0.9530 - val_loss: 0.2041 - val_acc: 0.9200\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 574s 6s/step - loss: 0.1245 - acc: 0.9555 - val_loss: 0.1904 - val_acc: 0.9260\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 566s 6s/step - loss: 0.1076 - acc: 0.9610 - val_loss: 0.1725 - val_acc: 0.9340\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 560s 6s/step - loss: 0.1061 - acc: 0.9590 - val_loss: 0.1674 - val_acc: 0.9320\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 572s 6s/step - loss: 0.0872 - acc: 0.9660 - val_loss: 0.1970 - val_acc: 0.9240\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 562s 6s/step - loss: 0.0806 - acc: 0.9690 - val_loss: 0.1773 - val_acc: 0.9310\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 586s 6s/step - loss: 0.0685 - acc: 0.9740 - val_loss: 0.1748 - val_acc: 0.9330\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 605s 6s/step - loss: 0.0682 - acc: 0.9720 - val_loss: 0.1735 - val_acc: 0.9320\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 609s 6s/step - loss: 0.0577 - acc: 0.9810 - val_loss: 0.1799 - val_acc: 0.9290\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 642s 6s/step - loss: 0.0514 - acc: 0.9805 - val_loss: 0.1736 - val_acc: 0.9400\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 593s 6s/step - loss: 0.0573 - acc: 0.9780 - val_loss: 0.1906 - val_acc: 0.9320\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 559s 6s/step - loss: 0.0495 - acc: 0.9815 - val_loss: 0.2195 - val_acc: 0.9230\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 562s 6s/step - loss: 0.0446 - acc: 0.9845 - val_loss: 0.1955 - val_acc: 0.9320\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 558s 6s/step - loss: 0.0407 - acc: 0.9865 - val_loss: 0.2055 - val_acc: 0.9290\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 554s 6s/step - loss: 0.0344 - acc: 0.9895 - val_loss: 0.2175 - val_acc: 0.9320\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 554s 6s/step - loss: 0.0355 - acc: 0.9870 - val_loss: 0.2204 - val_acc: 0.9270\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 552s 6s/step - loss: 0.0384 - acc: 0.9855 - val_loss: 0.2055 - val_acc: 0.9310\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 555s 6s/step - loss: 0.0262 - acc: 0.9910 - val_loss: 0.2006 - val_acc: 0.9330\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 566s 6s/step - loss: 0.0220 - acc: 0.9915 - val_loss: 0.2430 - val_acc: 0.9260\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 587s 6s/step - loss: 0.0353 - acc: 0.9870 - val_loss: 0.2166 - val_acc: 0.9310\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 629s 6s/step - loss: 0.0216 - acc: 0.9930 - val_loss: 0.2223 - val_acc: 0.9310\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 579s 6s/step - loss: 0.0230 - acc: 0.9925 - val_loss: 0.2305 - val_acc: 0.9300\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 583s 6s/step - loss: 0.0300 - acc: 0.9895 - val_loss: 0.2381 - val_acc: 0.9280\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 638s 6s/step - loss: 0.0228 - acc: 0.9905 - val_loss: 0.2528 - val_acc: 0.9240\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 560s 6s/step - loss: 0.0269 - acc: 0.9895 - val_loss: 0.3025 - val_acc: 0.9200\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 579s 6s/step - loss: 0.0235 - acc: 0.9905 - val_loss: 0.2791 - val_acc: 0.9250\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 604s 6s/step - loss: 0.0216 - acc: 0.9915 - val_loss: 0.2406 - val_acc: 0.9330\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 591s 6s/step - loss: 0.0178 - acc: 0.9935 - val_loss: 0.3269 - val_acc: 0.9210\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 573s 6s/step - loss: 0.0165 - acc: 0.9955 - val_loss: 0.2538 - val_acc: 0.9270\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 611s 6s/step - loss: 0.0153 - acc: 0.9955 - val_loss: 0.2553 - val_acc: 0.9300\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 1391s 14s/step - loss: 0.0135 - acc: 0.9965 - val_loss: 0.2509 - val_acc: 0.9360\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 2380s 24s/step - loss: 0.0220 - acc: 0.9925 - val_loss: 0.2324 - val_acc: 0.9360\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 1800s 18s/step - loss: 0.0095 - acc: 0.9980 - val_loss: 0.2758 - val_acc: 0.9310\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 1495s 15s/step - loss: 0.0119 - acc: 0.9955 - val_loss: 0.2740 - val_acc: 0.9240\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 1473s 15s/step - loss: 0.0115 - acc: 0.9975 - val_loss: 0.2701 - val_acc: 0.9390\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 1477s 15s/step - loss: 0.0143 - acc: 0.9940 - val_loss: 0.2654 - val_acc: 0.9290\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 1495s 15s/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.2683 - val_acc: 0.9290\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 795s 8s/step - loss: 0.0230 - acc: 0.9930 - val_loss: 0.2450 - val_acc: 0.9380\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 554s 6s/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.2563 - val_acc: 0.9330\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 546s 5s/step - loss: 0.0136 - acc: 0.9965 - val_loss: 0.3114 - val_acc: 0.9210\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 546s 5s/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.2800 - val_acc: 0.9330\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 548s 5s/step - loss: 0.0161 - acc: 0.9955 - val_loss: 0.3067 - val_acc: 0.9300\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n",
    "\n",
    "model.save('cats_and_dogs_small_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "test acc: 0.9359999942779541\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
