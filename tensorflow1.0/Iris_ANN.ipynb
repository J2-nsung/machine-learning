{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data path\n",
    "train_path = \"iris_training.csv\"\n",
    "test_path = \"iris_test.csv\"\n",
    "\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(120,)\n",
      "(30, 4)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(train_path, test_path, y_name='Species'):\n",
    "    # Return the iris dataset as (train_x, train_y), (test_x, test_y)\n",
    "    \n",
    "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    train_x, train_y = train, train.pop(y_name)\n",
    "    \n",
    "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    test_x, test_y = test, test.pop(y_name)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "# load data\n",
    "(train_x, train_y), (test_x, test_y) = load_data(train_path, test_path)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "display_step = 1 # 손실함수 출력 주기\n",
    "input_size = 4 # SepalLength, SepalWidth, PetalLength, PetalWidth\n",
    "hidden1_size = 256\n",
    "hidden2_size = 256\n",
    "output_size = 3 # Setosa, Versicolor, Virginica\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "y = tf.placeholder(tf.float32, shape=[None, output_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ANN(x):\n",
    "    W1 = tf.Variable(tf.random_normal(shape=[input_size, hidden1_size]))\n",
    "    b1 = tf.Variable(tf.random_normal(shape=[hidden1_size]))\n",
    "    H1_output = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "    \n",
    "    W2 = tf.Variable(tf.random_normal(shape=[hidden1_size, hidden2_size]))\n",
    "    b2 = tf.Variable(tf.random_normal(shape=[hidden2_size]))\n",
    "    H2_output = tf.nn.relu(tf.matmul(H1_output, W2) + b2)\n",
    "    \n",
    "    W_output = tf.Variable(tf.random_normal(shape=[hidden2_size, output_size]))\n",
    "    b_output = tf.Variable(tf.random_normal(shape=[output_size]))\n",
    "    logits = tf.matmul(H2_output, W_output) + b_output\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN모델 선언\n",
    "predicted_value = build_ANN(x)\n",
    "\n",
    "# 손실함수, 옵티마이저 정의\n",
    "# tf.nn.softmax_cross_entropy_with_logits 함수를 이용하여 활성함수를 적용하지 않은 output layer의\n",
    "# 결과값(logits)에 softmax 함수를 적용\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=predicted_value, labels=y))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 1, 손실함수(Loss): 4.867050\n",
      "반복(Epoch): 2, 손실함수(Loss): 4.234914\n",
      "반복(Epoch): 3, 손실함수(Loss): 3.602315\n",
      "반복(Epoch): 4, 손실함수(Loss): 3.002183\n",
      "반복(Epoch): 5, 손실함수(Loss): 2.543899\n",
      "반복(Epoch): 6, 손실함수(Loss): 2.218004\n",
      "반복(Epoch): 7, 손실함수(Loss): 1.948457\n",
      "반복(Epoch): 8, 손실함수(Loss): 1.776784\n",
      "반복(Epoch): 9, 손실함수(Loss): 1.636147\n",
      "반복(Epoch): 10, 손실함수(Loss): 1.440999\n",
      "반복(Epoch): 11, 손실함수(Loss): 1.181122\n",
      "반복(Epoch): 12, 손실함수(Loss): 0.892328\n",
      "반복(Epoch): 13, 손실함수(Loss): 0.605661\n",
      "반복(Epoch): 14, 손실함수(Loss): 0.343097\n",
      "반복(Epoch): 15, 손실함수(Loss): 0.127870\n",
      "반복(Epoch): 16, 손실함수(Loss): 0.088958\n",
      "반복(Epoch): 17, 손실함수(Loss): 0.185171\n",
      "반복(Epoch): 18, 손실함수(Loss): 0.307292\n",
      "반복(Epoch): 19, 손실함수(Loss): 0.372370\n",
      "반복(Epoch): 20, 손실함수(Loss): 0.321172\n",
      "반복(Epoch): 21, 손실함수(Loss): 0.198013\n",
      "반복(Epoch): 22, 손실함수(Loss): 0.084958\n",
      "반복(Epoch): 23, 손실함수(Loss): 0.025054\n",
      "반복(Epoch): 24, 손실함수(Loss): 0.014070\n",
      "반복(Epoch): 25, 손실함수(Loss): 0.018052\n",
      "반복(Epoch): 26, 손실함수(Loss): 0.031091\n",
      "반복(Epoch): 27, 손실함수(Loss): 0.045072\n",
      "반복(Epoch): 28, 손실함수(Loss): 0.055999\n",
      "반복(Epoch): 29, 손실함수(Loss): 0.061001\n",
      "반복(Epoch): 30, 손실함수(Loss): 0.059554\n",
      "반복(Epoch): 31, 손실함수(Loss): 0.052719\n",
      "반복(Epoch): 32, 손실함수(Loss): 0.042220\n",
      "반복(Epoch): 33, 손실함수(Loss): 0.030788\n",
      "반복(Epoch): 34, 손실함수(Loss): 0.020458\n",
      "반복(Epoch): 35, 손실함수(Loss): 0.015488\n",
      "반복(Epoch): 36, 손실함수(Loss): 0.011832\n",
      "반복(Epoch): 37, 손실함수(Loss): 0.010027\n",
      "반복(Epoch): 38, 손실함수(Loss): 0.010559\n",
      "반복(Epoch): 39, 손실함수(Loss): 0.015206\n",
      "반복(Epoch): 40, 손실함수(Loss): 0.019982\n",
      "반복(Epoch): 41, 손실함수(Loss): 0.022425\n",
      "반복(Epoch): 42, 손실함수(Loss): 0.022261\n",
      "반복(Epoch): 43, 손실함수(Loss): 0.019735\n",
      "반복(Epoch): 44, 손실함수(Loss): 0.015489\n",
      "반복(Epoch): 45, 손실함수(Loss): 0.011006\n",
      "반복(Epoch): 46, 손실함수(Loss): 0.008749\n",
      "반복(Epoch): 47, 손실함수(Loss): 0.008036\n",
      "반복(Epoch): 48, 손실함수(Loss): 0.008693\n",
      "반복(Epoch): 49, 손실함수(Loss): 0.009873\n",
      "반복(Epoch): 50, 손실함수(Loss): 0.011195\n",
      "반복(Epoch): 51, 손실함수(Loss): 0.012010\n",
      "반복(Epoch): 52, 손실함수(Loss): 0.012284\n",
      "반복(Epoch): 53, 손실함수(Loss): 0.012068\n",
      "반복(Epoch): 54, 손실함수(Loss): 0.011403\n",
      "반복(Epoch): 55, 손실함수(Loss): 0.010329\n",
      "반복(Epoch): 56, 손실함수(Loss): 0.008968\n",
      "반복(Epoch): 57, 손실함수(Loss): 0.007458\n",
      "반복(Epoch): 58, 손실함수(Loss): 0.006525\n",
      "반복(Epoch): 59, 손실함수(Loss): 0.006168\n",
      "반복(Epoch): 60, 손실함수(Loss): 0.006490\n",
      "반복(Epoch): 61, 손실함수(Loss): 0.006853\n",
      "반복(Epoch): 62, 손실함수(Loss): 0.007356\n",
      "반복(Epoch): 63, 손실함수(Loss): 0.007468\n",
      "반복(Epoch): 64, 손실함수(Loss): 0.006778\n",
      "반복(Epoch): 65, 손실함수(Loss): 0.006007\n",
      "반복(Epoch): 66, 손실함수(Loss): 0.005410\n",
      "반복(Epoch): 67, 손실함수(Loss): 0.005025\n",
      "반복(Epoch): 68, 손실함수(Loss): 0.004854\n",
      "반복(Epoch): 69, 손실함수(Loss): 0.004941\n",
      "반복(Epoch): 70, 손실함수(Loss): 0.005220\n",
      "반복(Epoch): 71, 손실함수(Loss): 0.005215\n",
      "반복(Epoch): 72, 손실함수(Loss): 0.004854\n",
      "반복(Epoch): 73, 손실함수(Loss): 0.004396\n",
      "반복(Epoch): 74, 손실함수(Loss): 0.004079\n",
      "반복(Epoch): 75, 손실함수(Loss): 0.003915\n",
      "반복(Epoch): 76, 손실함수(Loss): 0.003818\n",
      "반복(Epoch): 77, 손실함수(Loss): 0.003788\n",
      "반복(Epoch): 78, 손실함수(Loss): 0.003805\n",
      "반복(Epoch): 79, 손실함수(Loss): 0.003719\n",
      "반복(Epoch): 80, 손실함수(Loss): 0.003471\n",
      "반복(Epoch): 81, 손실함수(Loss): 0.003188\n",
      "반복(Epoch): 82, 손실함수(Loss): 0.003008\n",
      "반복(Epoch): 83, 손실함수(Loss): 0.002953\n",
      "반복(Epoch): 84, 손실함수(Loss): 0.002936\n",
      "반복(Epoch): 85, 손실함수(Loss): 0.002872\n",
      "반복(Epoch): 86, 손실함수(Loss): 0.002755\n",
      "반복(Epoch): 87, 손실함수(Loss): 0.002589\n",
      "반복(Epoch): 88, 손실함수(Loss): 0.002387\n",
      "반복(Epoch): 89, 손실함수(Loss): 0.002218\n",
      "반복(Epoch): 90, 손실함수(Loss): 0.002257\n",
      "반복(Epoch): 91, 손실함수(Loss): 0.002215\n",
      "반복(Epoch): 92, 손실함수(Loss): 0.001988\n",
      "반복(Epoch): 93, 손실함수(Loss): 0.001900\n",
      "반복(Epoch): 94, 손실함수(Loss): 0.001883\n",
      "반복(Epoch): 95, 손실함수(Loss): 0.001835\n",
      "반복(Epoch): 96, 손실함수(Loss): 0.001742\n",
      "반복(Epoch): 97, 손실함수(Loss): 0.001621\n",
      "반복(Epoch): 98, 손실함수(Loss): 0.001519\n",
      "반복(Epoch): 99, 손실함수(Loss): 0.001481\n",
      "반복(Epoch): 100, 손실함수(Loss): 0.001435\n",
      "정확도(Accuracy): 0.966667\n"
     ]
    }
   ],
   "source": [
    "# 세션을 열고 그래프 실행\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 지정된 횟수만큼 최적화\n",
    "    for epoch in range(num_epochs):\n",
    "        average_loss = 0.\n",
    "        \n",
    "        batch_x = train_x.values\n",
    "        batch_y = sess.run(tf.one_hot(train_y.values, 3))\n",
    "        # 옵티마이저 실행, 파라미터 업데이트\n",
    "        _, current_loss = sess.run([train_step, loss], feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        # 평균 손실 측정\n",
    "        average_loss += current_loss / batch_x.shape[0]\n",
    "            \n",
    "        #지정된 epoch마다 학습결과 출력\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"반복(Epoch): %d, 손실함수(Loss): %f\" % ((epoch+1), average_loss))\n",
    "            \n",
    "    # 정확도 출력\n",
    "    correct_prediction = tf.equal(tf.argmax(predicted_value, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    print(\"정확도(Accuracy): %f\" % (accuracy.eval(feed_dict={x: test_x.values, y: sess.run(tf.one_hot(test_y.values, 3))})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
